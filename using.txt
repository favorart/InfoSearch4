
hadoop run_is4.sh
# map_is4.py, 'red_is4.py <-f <max>|-s 9>'

-f|-s - Фибоначчи или Simple9

#  !!! Сжатию Фибоначчи нужно задать правильный параметр =
#  !!! = количеству IDшников URLов, которые нужно записать в индекс.
#  !!! МАКСИМАЛЬНОЕ ЧИСЛО ФИБОНАЧЧИ, которые надо преподсчитать!

python      reshape.py <-f <max>|-s 9> <in_data_path> <out_binary_path> <out_index_path>
python  InfoSearch4.py <-f <max>|-s 9> <in_binary_path> <in_index_path> <in_urls_path>

type "C:\data\povarenok.ru\1_1000\docs-000.txt" | python map_is4.py         | python sort.py > data\povarenok1000_mapped_s.txt
type data\povarenok1000_mapped_s.txt            | python red_is4.py -s 9 -e | python sort.py > data\povarenok1000s_reduced_s.txt

type data\povarenok1000_mapped1.txt | python sort.py > data\povarenok1000_mapped_s.txt

python reshape.py -s 9 -e -d data\povarenok1000s_reduced_s.txt

python BoolSearch.py -w is2 -i index.txt -b backward.bin -u urls.txt

-------------------------------------------------------------------------------------------
Files format:

dlens.txt:     N    id,len id,len ...
index.txt:     { norm : { "ids": [offset:size], "lens": [offset:size],
                          "posits": [offset,size,size,...], "hashes": [offset,size,size,...] }
backward.bin:  for one norm [ids] + [lens] + [posits] + [hashes]
-------------------------------------------------------------------------------------------

v Отдельно координаты и отдельно doc_ids, чтобы можно было раздельно поднимать
v Прогнать marks булевым поиском marks поднимаются вообще? AND --> 251
v Прогнать marks черновым ранжированием, найти границу - >80% marks появляются в выдаче --> N
v Прогнать marks пассажным алгоритмом


'AND'.join([ 'OR'.join(('word1')), 'OR'.join(('word2', 'syn1', ...)), ... ])
v неправильная раскладка, прогнать инвертированно
v список стоп слов, вместе со стоп словами и без стоп словами

- ?много-процессность?

